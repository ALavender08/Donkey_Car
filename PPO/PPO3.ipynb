{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe2c9ef-edf9-40e9-b72b-f49d715b0d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import gym_donkeycar\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow\n",
    "import shimmy\n",
    "from rich.live import Live\n",
    "import stable_baselines3\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153e811c-cdd9-4bdb-80ab-cfa8be254d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "DONKEY_GYM = True\n",
    "DONKEY_SIM_PATH = \"remote\"\n",
    "DONKEY_GYM_ENV_NAME = \"donkey-generated-track-v0\"\n",
    "body_style = \"car01\"\n",
    "body_rgb = (128, 128, 128)\n",
    "car_name = \"PPO3\"\n",
    "font_size = 100\n",
    "WEB_CONTROL_PORT = int(os.getenv(\"WEB_CONTROL_PORT\", 8887))\n",
    "port = 9091"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b17fbafc-04ed-458f-a24e-b7fe8f051d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/mnt/d/donkeycar_model/PPO3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae91565-d9fe-4621-b3c2-4b571a2096ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = { \"DONKEY_GYM\":DONKEY_GYM, \"DONKEY_SIM_PATH\":DONKEY_SIM_PATH, \"DONKEY_GYM_ENV_NAME\":DONKEY_GYM_ENV_NAME, \n",
    "         \"body_style\":body_style, \"body_rgb\":body_rgb, \"car_name\":car_name, \"font_size\":font_size, \n",
    "         \"WEB_CONTROL_PORT\" : WEB_CONTROL_PORT, \"port\" : port }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9cf5cfd-c37a-4e6d-8862-c23292b6d595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_donkeycar.core.client:connecting to localhost:9091 \n",
      "INFO:gym_donkeycar.envs.donkey_sim:on need car config\n",
      "INFO:gym_donkeycar.envs.donkey_sim:sending car config.\n",
      "INFO:gym_donkeycar.envs.donkey_sim:sim started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting DonkeyGym env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 21.62 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 6.97 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 4.22 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 23.02 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 23.1 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 23.05 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 22.78 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 23.42 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 23.17 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 23.29 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 22.57 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 23.19 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 23.59 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 4.25 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 23.05 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 4.38 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 24.59 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 24.42 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 24.59 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 24.77 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 25.62 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 4.88 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 24.8 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 23.09 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 23.7 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 25.09 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 24.12 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 24.85 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 4.31 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 3.17 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 4.23 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 4.33 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 4.22 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 4.25 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 4.22 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 4.28 seconds\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"donkey-minimonaco-track-v0\", conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8571d43d-49f5-4726-818f-6c40a48c754f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 500`, after every 7 untruncated mini-batches, there will be a truncated mini-batch of size 52\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=500 and n_envs=1)\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/utils.py:573: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "  return th.as_tensor(obs, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing 2500 : 185.11247068491355\n",
      "testing 5000 : 334.39704018058103\n",
      "testing 7500 : 38.22020336138151\n",
      "testing 10000 : 290.59589525966373\n",
      "testing 12500 : 339.08916299894423\n",
      "testing 15000 : 74.85773765797478\n",
      "testing 17500 : 287.63059019855314\n",
      "testing 20000 : 268.5555194628911\n",
      "testing 22500 : 2290.0604888723365\n",
      "testing 25000 : 307.39624196928094\n",
      "testing 27500 : 135.1527983269416\n",
      "testing 30000 : 110.19581203299254\n",
      "testing 32500 : -1.0000007970221527\n",
      "testing 35000 : -1.0000007609731285\n",
      "testing 37500 : 15.426144382458313\n",
      "testing 40000 : 347.4381743983106\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m obs = env.reset()\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     action, _states = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     obs, reward, done, info = env.step(action)\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# print (reward, done)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/base_class.py:557\u001b[39m, in \u001b[36mBaseAlgorithm.predict\u001b[39m\u001b[34m(self, observation, state, episode_start, deterministic)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\n\u001b[32m    538\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    539\u001b[39m     observation: Union[np.ndarray, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, np.ndarray]],\n\u001b[32m   (...)\u001b[39m\u001b[32m    542\u001b[39m     deterministic: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    543\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[np.ndarray, Optional[\u001b[38;5;28mtuple\u001b[39m[np.ndarray, ...]]]:\n\u001b[32m    544\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    545\u001b[39m \u001b[33;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[32m    546\u001b[39m \u001b[33;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    555\u001b[39m \u001b[33;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[32m    556\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/policies.py:368\u001b[39m, in \u001b[36mBasePolicy.predict\u001b[39m\u001b[34m(self, observation, state, episode_start, deterministic)\u001b[39m\n\u001b[32m    365\u001b[39m obs_tensor, vectorized_env = \u001b[38;5;28mself\u001b[39m.obs_to_tensor(observation)\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m th.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     actions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[38;5;66;03m# Convert to numpy, and reshape to the original action shape\u001b[39;00m\n\u001b[32m    370\u001b[39m actions = actions.cpu().numpy().reshape((-\u001b[32m1\u001b[39m, *\u001b[38;5;28mself\u001b[39m.action_space.shape))  \u001b[38;5;66;03m# type: ignore[misc, assignment]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/policies.py:717\u001b[39m, in \u001b[36mActorCriticPolicy._predict\u001b[39m\u001b[34m(self, observation, deterministic)\u001b[39m\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation: PyTorchObs, deterministic: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m) -> th.Tensor:\n\u001b[32m    710\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    711\u001b[39m \u001b[33;03m    Get the action according to the policy for a given observation.\u001b[39;00m\n\u001b[32m    712\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    715\u001b[39m \u001b[33;03m    :return: Taken action according to the policy\u001b[39;00m\n\u001b[32m    716\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m717\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m.get_actions(deterministic=deterministic)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/policies.py:750\u001b[39m, in \u001b[36mActorCriticPolicy.get_distribution\u001b[39m\u001b[34m(self, obs)\u001b[39m\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_distribution\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs: PyTorchObs) -> Distribution:\n\u001b[32m    744\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[33;03m    Get the current policy distribution given the observations.\u001b[39;00m\n\u001b[32m    746\u001b[39m \n\u001b[32m    747\u001b[39m \u001b[33;03m    :param obs:\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[33;03m    :return: the action distribution.\u001b[39;00m\n\u001b[32m    749\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m     features = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpi_features_extractor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m     latent_pi = \u001b[38;5;28mself\u001b[39m.mlp_extractor.forward_actor(features)\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_action_dist_from_latent(latent_pi)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/policies.py:131\u001b[39m, in \u001b[36mBaseModel.extract_features\u001b[39m\u001b[34m(self, obs, features_extractor)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[33;03mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[32m    125\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    128\u001b[39m \u001b[33;03m:return: The extracted features\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    130\u001b[39m preprocessed_obs = preprocess_obs(obs, \u001b[38;5;28mself\u001b[39m.observation_space, normalize_images=\u001b[38;5;28mself\u001b[39m.normalize_images)\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeatures_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed_obs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/torch_layers.py:107\u001b[39m, in \u001b[36mNatureCNN.forward\u001b[39m\u001b[34m(self, observations)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, observations: th.Tensor) -> th.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    # preparation\n",
    "    if i == 0:\n",
    "        model = PPO(\"CnnPolicy\", env, n_steps=500, verbose=0, learning_rate=0.0003*0.5 )\n",
    "        Log={\"TestReward\":[]}\n",
    "\n",
    "    # training\n",
    "    obs = env.reset()\n",
    "    model.learn(total_timesteps=2500, progress_bar=0)\n",
    "    model.save(f'{folder}{(i+1)*2500}.pth')\n",
    "\n",
    "    # testing\n",
    "    tem = 0\n",
    "    for _ in range(20):\n",
    "        obs = env.reset()\n",
    "        while True:\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            # print (reward, done)\n",
    "            env.render()\n",
    "            tem += reward\n",
    "            if done: break\n",
    "    Log[\"TestReward\"].append(tem/20)\n",
    "    print(f\"testing {(i+1)*2500} : {tem/20}\")\n",
    "    np.save(f\"{folder}/Log_PPO3-{(i+1)*2500}.npy\", Log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99bbb982-83fc-45be-9705-e059ab5ff08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e11a21ce-461f-46bc-a1c4-bdde300d4317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_donkeycar.core.client:connecting to localhost:9091 \n",
      "INFO:gym_donkeycar.envs.donkey_sim:on need car config\n",
      "INFO:gym_donkeycar.envs.donkey_sim:sending car config.\n",
      "INFO:gym_donkeycar.envs.donkey_sim:sim started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting DonkeyGym env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 36.59 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 36.08 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 36.36 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 36.9 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 36.11 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 36.48 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 36.58 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 36.32 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 36.2 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 36.06 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 36.51 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 36.55 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 36.46 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 35.88 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 36.42 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 36.19 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 36.54 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 36.55 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20784.638129738538\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"donkey-minimonaco-track-v0\", conf=conf)\n",
    "num = 42500\n",
    "test_model = PPO.load(f\"{folder}{num}.pth\")\n",
    "obs = env.reset()\n",
    "tem = 0\n",
    "while True:\n",
    "    action, _states = test_model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    # print (reward, done)\n",
    "    env.render()\n",
    "    tem += reward\n",
    "    if done: break\n",
    "print(tem)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12e72234-173a-48d5-9551-33a5b8fa9b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/utils.py:573: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "  return th.as_tensor(obs, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing 2500 : 152.31239330536192\n",
      "testing 5000 : 202.03199906128916\n",
      "testing 7500 : 208.79215585344895\n",
      "testing 10000 : 413.5498364176436\n",
      "testing 12500 : 430.65198737884475\n",
      "testing 15000 : 391.981493625345\n",
      "testing 17500 : 183.22719092967952\n",
      "testing 20000 : 133.80995716659058\n",
      "testing 22500 : 172.01794990224988\n",
      "testing 25000 : 183.06078397712196\n",
      "testing 27500 : 170.91418507108727\n",
      "testing 30000 : 1041.2360410712813\n",
      "testing 32500 : 240.0998285393624\n",
      "testing 35000 : 659.7961742399292\n",
      "testing 37500 : 569.2365144693435\n",
      "testing 40000 : 267.3136376897365\n",
      "testing 42500 : 387.65555844022185\n",
      "testing 45000 : 270.66346621729383\n",
      "testing 47500 : 1057.6555655444745\n",
      "testing 50000 : 306.2825141546318\n",
      "testing 52500 : 182.63049974248364\n",
      "testing 55000 : 130.56301061812496\n",
      "testing 57500 : 119.58488299028002\n",
      "testing 60000 : 132.00622259151345\n",
      "testing 62500 : 164.9433126770527\n",
      "testing 65000 : 192.43429789370273\n",
      "testing 67500 : 248.05083544029836\n",
      "testing 70000 : 195.19282177703764\n",
      "testing 72500 : 198.31634465463944\n",
      "testing 75000 : 182.41325702157093\n",
      "testing 77500 : 189.15559325154305\n",
      "testing 80000 : 188.0447262027662\n",
      "testing 82500 : 175.94894147194816\n",
      "testing 85000 : 198.25462982803126\n",
      "testing 87500 : 233.04425278721152\n",
      "testing 90000 : 169.646315251323\n",
      "testing 92500 : 366.3694847876702\n",
      "testing 95000 : 252.9056158785018\n",
      "testing 97500 : 603.1715195285811\n",
      "testing 100000 : 631.7461640056342\n",
      "testing 102500 : 253.54933296681048\n",
      "testing 105000 : 228.90345277676997\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[32m     10\u001b[39m obs = env.reset()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m model.save(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mLoad_File+i*\u001b[32m2500\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pth\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# testing\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:311\u001b[39m, in \u001b[36mPPO.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlearn\u001b[39m(\n\u001b[32m    303\u001b[39m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[32m    304\u001b[39m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    309\u001b[39m     progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    310\u001b[39m ) -> SelfPPO:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:337\u001b[39m, in \u001b[36mOnPolicyAlgorithm.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    334\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ep_info_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28mself\u001b[39m.dump_logs(iteration)\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m callback.on_training_end()\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:207\u001b[39m, in \u001b[36mPPO.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    205\u001b[39m approx_kl_divs = []\n\u001b[32m    206\u001b[39m \u001b[38;5;66;03m# Do a complete pass on the rollout buffer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrollout_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrollout_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mactions\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspaces\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDiscrete\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Convert discrete action from float to long\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/buffers.py:505\u001b[39m, in \u001b[36mRolloutBuffer.get\u001b[39m\u001b[34m(self, batch_size)\u001b[39m\n\u001b[32m    503\u001b[39m start_idx = \u001b[32m0\u001b[39m\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m start_idx < \u001b[38;5;28mself\u001b[39m.buffer_size * \u001b[38;5;28mself\u001b[39m.n_envs:\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m     start_idx += batch_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/buffers.py:521\u001b[39m, in \u001b[36mRolloutBuffer._get_samples\u001b[39m\u001b[34m(self, batch_inds, env)\u001b[39m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_samples\u001b[39m(\n\u001b[32m    509\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    510\u001b[39m     batch_inds: np.ndarray,\n\u001b[32m    511\u001b[39m     env: Optional[VecNormalize] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    512\u001b[39m ) -> RolloutBufferSamples:\n\u001b[32m    513\u001b[39m     data = (\n\u001b[32m    514\u001b[39m         \u001b[38;5;28mself\u001b[39m.observations[batch_inds],\n\u001b[32m    515\u001b[39m         \u001b[38;5;28mself\u001b[39m.actions[batch_inds],\n\u001b[32m   (...)\u001b[39m\u001b[32m    519\u001b[39m         \u001b[38;5;28mself\u001b[39m.returns[batch_inds].flatten(),\n\u001b[32m    520\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m RolloutBufferSamples(*\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m.to_torch, data)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/buffers.py:139\u001b[39m, in \u001b[36mBaseBuffer.to_torch\u001b[39m\u001b[34m(self, array, copy)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[33;03mConvert a numpy array to a PyTorch tensor.\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[33;03mNote: it copies the data by default\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    136\u001b[39m \u001b[33;03m:return:\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m th.as_tensor(array, device=\u001b[38;5;28mself\u001b[39m.device)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "Load_File = 42500\n",
    "for i in range(1000):\n",
    "    # preparation\n",
    "    if i == 0:\n",
    "        # model = PPO(\"CnnPolicy\", env, n_steps=500, verbose=0, learning_rate=0.0003*0.5 )\n",
    "        model = PPO.load(f\"{folder}{Load_File}.pth\",  env = env)\n",
    "        Log= np.load(f\"{folder}Log_PPO3-{Load_File-2500}.npy\", allow_pickle=True).item()\n",
    "\n",
    "    # training\n",
    "    obs = env.reset()\n",
    "    model.learn(total_timesteps=2500, progress_bar=0)\n",
    "    model.save(f'{folder}{Load_File+i*2500}.pth')\n",
    "\n",
    "    # testing\n",
    "    tem = 0\n",
    "    for _ in range(20):\n",
    "        obs = env.reset()\n",
    "        while True:\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            # print (reward, done)\n",
    "            env.render()\n",
    "            tem += reward\n",
    "            if done: break\n",
    "    Log[\"TestReward\"].append(tem/20)\n",
    "    print(f\"testing {(i+1)*2500} : {tem/20}\")\n",
    "    np.save(f\"{folder}/Log_PPO3-{Load_File+i*2500}.npy\", Log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce980c-d254-4e51-9576-ead31c6c3269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
