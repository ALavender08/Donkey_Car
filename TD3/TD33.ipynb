{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe2c9ef-edf9-40e9-b72b-f49d715b0d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import gym_donkeycar\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow\n",
    "import shimmy\n",
    "from rich.live import Live\n",
    "import stable_baselines3\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3 import TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153e811c-cdd9-4bdb-80ab-cfa8be254d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "DONKEY_GYM = True\n",
    "DONKEY_SIM_PATH = \"remote\"\n",
    "DONKEY_GYM_ENV_NAME = \"donkey-generated-track-v0\"\n",
    "body_style = \"car01\"\n",
    "body_rgb = (128, 128, 128)\n",
    "car_name = \"TD33\"\n",
    "font_size = 100\n",
    "WEB_CONTROL_PORT = int(os.getenv(\"WEB_CONTROL_PORT\", 8887))\n",
    "port = 9091"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36313f51-71b1-4da6-9ef6-3ec7def8699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/mnt/c/Users/user/OneDrive/Desktop/DonkeyCar/TD33'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae91565-d9fe-4621-b3c2-4b571a2096ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = { \"DONKEY_GYM\":DONKEY_GYM, \"DONKEY_SIM_PATH\":DONKEY_SIM_PATH, \"DONKEY_GYM_ENV_NAME\":DONKEY_GYM_ENV_NAME, \n",
    "         \"body_style\":body_style, \"body_rgb\":body_rgb, \"car_name\":car_name, \"font_size\":font_size, \n",
    "         \"WEB_CONTROL_PORT\" : WEB_CONTROL_PORT, \"port\" : port }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "804ca74f-b75f-4e51-90b3-e4074901877d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_donkeycar.core.client:connecting to localhost:9091 \n",
      "/home/user/miniconda3/envs/donkey/lib/python3.11/site-packages/gym/spaces/box.py:78: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "INFO:gym_donkeycar.envs.donkey_sim:on need car config\n",
      "INFO:gym_donkeycar.envs.donkey_sim:sending car config.\n",
      "INFO:gym_donkeycar.envs.donkey_sim:sim started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting DonkeyGym env\n",
      "Setting default: start_delay 5.0\n",
      "Setting default: max_cte 8.0\n",
      "Setting default: frame_skip 1\n",
      "Setting default: cam_resolution (120, 160, 3)\n",
      "Setting default: log_level 20\n",
      "Setting default: host localhost\n",
      "Setting default: steer_limit 1.0\n",
      "Setting default: throttle_min 0.0\n",
      "Setting default: throttle_max 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 4.39 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 22.57 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 26.34 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 30.68 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 33.77 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 8.82 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 5.09 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 7.13 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 6.05 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 6.37 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 17.06 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 12.29 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 23.35 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 13.98 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 14.76 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 21.88 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 19.77 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 10.84 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 11.5 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 26.47 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 20.84 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 22.67 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 4.48 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 4.19 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 28.17 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 16.25 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 5.72 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 11.44 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 33.19 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 4.28 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 5.62 seconds\n",
      "INFO:gym_donkeycar.envs.donkey_sim:New lap time: 16.94 seconds\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"donkey-minimonaco-track-v0\", conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a45c92cb-9ccc-40ea-94ef-dff746595f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.td3.policies import TD3Policy\n",
    "import torch \n",
    "\n",
    "class CustomTD3Policy(TD3Policy):\n",
    "    def make_actor_critic_optimizer(self):\n",
    "        self.actor.optimizer = torch.optim.Adam(self.actor.parameters(), lr=0.0000005 )\n",
    "        self.critic.optimizer = torch.optim.Adam(self.critic.parameters(), lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2799940-ac5a-4fe6-bf40-b7d7659e0bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/utils.py:488: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "  return th.as_tensor(obs, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing 2500 : 15.187656265288425\n",
      "testing 5000 : 14.917359500218804\n",
      "testing 7500 : 14.695888778824358\n",
      "testing 10000 : 15.033650641146105\n",
      "testing 12500 : 15.173929330098545\n",
      "testing 15000 : 15.00996042778587\n",
      "testing 17500 : 14.964143304066369\n",
      "testing 20000 : 15.07057471397604\n",
      "testing 22500 : 14.897920761234678\n",
      "testing 25000 : 14.829103073626637\n",
      "testing 27500 : 15.146632492142022\n",
      "testing 30000 : 14.74293037104431\n",
      "testing 32500 : 14.805279757758816\n",
      "testing 35000 : 15.306853955798434\n",
      "testing 37500 : 15.04897300140062\n",
      "testing 40000 : 14.920343049910901\n",
      "testing 42500 : 15.371799073594469\n",
      "testing 45000 : 15.473024634171583\n",
      "testing 47500 : 15.099807051808483\n",
      "testing 50000 : 14.721648626519572\n",
      "testing 52500 : 14.920723988866436\n",
      "testing 55000 : 15.275035143196543\n",
      "testing 57500 : 13.789993369928576\n",
      "testing 60000 : 14.531772666070328\n",
      "testing 62500 : 14.718462023473109\n",
      "testing 65000 : 14.233821964314634\n",
      "testing 67500 : 14.959592151150805\n",
      "testing 70000 : 14.653437297708928\n",
      "testing 72500 : 14.498835061998937\n",
      "testing 75000 : 14.27819771932358\n",
      "testing 77500 : 14.802548738899446\n",
      "testing 80000 : 14.27795091960932\n",
      "testing 82500 : 14.079883520026542\n",
      "testing 85000 : 15.183297577763105\n",
      "testing 87500 : 14.924323767390433\n",
      "testing 90000 : 14.756590197553802\n",
      "testing 92500 : 14.751650488382811\n",
      "testing 95000 : 14.669350879938492\n",
      "testing 97500 : 14.270158366933554\n",
      "testing 100000 : 14.604591498108153\n",
      "testing 102500 : 14.6364090259265\n",
      "testing 105000 : 14.613731391899908\n",
      "testing 107500 : 14.706263441626465\n",
      "testing 110000 : 14.681763289836192\n",
      "testing 112500 : 14.134656381210553\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[32m      9\u001b[39m obs = env.reset()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m model.learn(total_timesteps=\u001b[32m2500\u001b[39m, progress_bar=\u001b[32m0\u001b[39m)\n\u001b[32m     11\u001b[39m model.save(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(i+\u001b[32m1\u001b[39m)*\u001b[32m2500\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pth\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# testing\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/td3/td3.py:222\u001b[39m, in \u001b[36mTD3.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlearn\u001b[39m(\n\u001b[32m    214\u001b[39m     \u001b[38;5;28mself\u001b[39m: SelfTD3,\n\u001b[32m    215\u001b[39m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    220\u001b[39m     progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    221\u001b[39m ) -> SelfTD3:\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().learn(\n\u001b[32m    223\u001b[39m         total_timesteps=total_timesteps,\n\u001b[32m    224\u001b[39m         callback=callback,\n\u001b[32m    225\u001b[39m         log_interval=log_interval,\n\u001b[32m    226\u001b[39m         tb_log_name=tb_log_name,\n\u001b[32m    227\u001b[39m         reset_num_timesteps=reset_num_timesteps,\n\u001b[32m    228\u001b[39m         progress_bar=progress_bar,\n\u001b[32m    229\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/off_policy_algorithm.py:328\u001b[39m, in \u001b[36mOffPolicyAlgorithm.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.train_freq, TrainFreq)  \u001b[38;5;66;03m# check done in _setup_learn()\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_timesteps < total_timesteps:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     rollout = \u001b[38;5;28mself\u001b[39m.collect_rollouts(\n\u001b[32m    329\u001b[39m         \u001b[38;5;28mself\u001b[39m.env,\n\u001b[32m    330\u001b[39m         train_freq=\u001b[38;5;28mself\u001b[39m.train_freq,\n\u001b[32m    331\u001b[39m         action_noise=\u001b[38;5;28mself\u001b[39m.action_noise,\n\u001b[32m    332\u001b[39m         callback=callback,\n\u001b[32m    333\u001b[39m         learning_starts=\u001b[38;5;28mself\u001b[39m.learning_starts,\n\u001b[32m    334\u001b[39m         replay_buffer=\u001b[38;5;28mself\u001b[39m.replay_buffer,\n\u001b[32m    335\u001b[39m         log_interval=log_interval,\n\u001b[32m    336\u001b[39m     )\n\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rollout.continue_training:\n\u001b[32m    339\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/off_policy_algorithm.py:560\u001b[39m, in \u001b[36mOffPolicyAlgorithm.collect_rollouts\u001b[39m\u001b[34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[39m\n\u001b[32m    557\u001b[39m actions, buffer_actions = \u001b[38;5;28mself\u001b[39m._sample_action(learning_starts, action_noise, env.num_envs)\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m new_obs, rewards, dones, infos = env.step(actions)\n\u001b[32m    562\u001b[39m \u001b[38;5;28mself\u001b[39m.num_timesteps += env.num_envs\n\u001b[32m    563\u001b[39m num_collected_steps += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:222\u001b[39m, in \u001b[36mVecEnv.step\u001b[39m\u001b[34m(self, actions)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    216\u001b[39m \u001b[33;03mStep the environments with the given action\u001b[39;00m\n\u001b[32m    217\u001b[39m \n\u001b[32m    218\u001b[39m \u001b[33;03m:param actions: the action\u001b[39;00m\n\u001b[32m    219\u001b[39m \u001b[33;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[38;5;28mself\u001b[39m.step_async(actions)\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.step_wait()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/vec_env/vec_transpose.py:97\u001b[39m, in \u001b[36mVecTransposeImage.step_wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> VecEnvStepReturn:\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     observations, rewards, dones, infos = \u001b[38;5;28mself\u001b[39m.venv.step_wait()\n\u001b[32m     99\u001b[39m     \u001b[38;5;66;03m# Transpose the terminal observations\u001b[39;00m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx, done \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dones):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:71\u001b[39m, in \u001b[36mDummyVecEnv.step_wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.buf_dones[env_idx]:\n\u001b[32m     69\u001b[39m         \u001b[38;5;66;03m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[32m     70\u001b[39m         \u001b[38;5;28mself\u001b[39m.buf_infos[env_idx][\u001b[33m\"\u001b[39m\u001b[33mterminal_observation\u001b[39m\u001b[33m\"\u001b[39m] = obs\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m         obs, \u001b[38;5;28mself\u001b[39m.reset_infos[env_idx] = \u001b[38;5;28mself\u001b[39m.envs[env_idx].reset()\n\u001b[32m     72\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_obs(env_idx, obs)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._obs_from_buf(), np.copy(\u001b[38;5;28mself\u001b[39m.buf_rews), np.copy(\u001b[38;5;28mself\u001b[39m.buf_dones), deepcopy(\u001b[38;5;28mself\u001b[39m.buf_infos))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/stable_baselines3/common/monitor.py:83\u001b[39m, in \u001b[36mMonitor.reset\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected you to pass keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m into reset\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mself\u001b[39m.current_reset_info[key] = value\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env.reset(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/shimmy/openai_gym_compatibility.py:234\u001b[39m, in \u001b[36mGymV21CompatibilityV0.reset\u001b[39m\u001b[34m(self, seed, options)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    230\u001b[39m     warn(\n\u001b[32m    231\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGym v21 environment do not accept options as a reset parameter, options=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    232\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m obs = \u001b[38;5;28mself\u001b[39m.gym_env.reset()\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.render_mode == \u001b[33m\"\u001b[39m\u001b[33mhuman\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    237\u001b[39m     \u001b[38;5;28mself\u001b[39m.render()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/donkey/lib/python3.11/site-packages/gym/wrappers/order_enforcing.py:18\u001b[39m, in \u001b[36mOrderEnforcing.reset\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mself\u001b[39m._has_reset = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env.reset(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/gym-donkeycar/gym_donkeycar/envs/donkey_env.py:145\u001b[39m, in \u001b[36mDonkeyEnv.reset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28mself\u001b[39m.viewer.reset()\n\u001b[32m    144\u001b[39m \u001b[38;5;28mself\u001b[39m.viewer.handler.send_control(\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1.0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m time.sleep(\u001b[32m0.1\u001b[39m)\n\u001b[32m    146\u001b[39m observation, reward, done, info = \u001b[38;5;28mself\u001b[39m.viewer.observe()\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m observation\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    if i == 0:\n",
    "        n_actions = env.action_space.shape[-1]\n",
    "        action_noise = stable_baselines3.common.noise.NormalActionNoise(mean=0.1*np.ones(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "        model = TD3(CustomTD3Policy, env, verbose = 0, buffer_size=10000, action_noise = action_noise )\n",
    "        Log={\"TestReward\":[]}\n",
    "\n",
    "    # training\n",
    "    obs = env.reset()\n",
    "    model.learn(total_timesteps=2500, progress_bar=0)\n",
    "    model.save(f'{folder}/{(i+1)*2500}.pth')\n",
    "\n",
    "    # testing\n",
    "    tem = 0\n",
    "    for _ in range(20):\n",
    "        obs = env.reset()\n",
    "        while True:\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            # print (reward, done)\n",
    "            env.render()\n",
    "            tem += reward\n",
    "            if done: break\n",
    "    Log[\"TestReward\"].append(tem/20)\n",
    "    print(f\"testing {(i+1)*2500} : {tem/20}\")\n",
    "    np.save(f\"{folder}/Log_TD33-{(i+1)*2500}.npy\", Log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99bbb982-83fc-45be-9705-e059ab5ff08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11a21ce-461f-46bc-a1c4-bdde300d4317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
